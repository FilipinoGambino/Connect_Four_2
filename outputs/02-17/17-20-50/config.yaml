#defaults:
#- override hydra/job_logging: colorlog
#- override hydra/hydra_logging: colorlog

hydra:
  run:
    dir: ./outputs/${now:%m-%d}/${now:%H-%M-%S}

name: student_phase3
## WANDB params
# The wandb project name
project: ConnectX
# The wandb user to log to
entity: filipinogambino
# The wandb group for the run
group: feb_run

# Parameters to overwrite
use_mixed_precision: False
total_steps: 1e6
batch_size: 8
checkpoint_freq: 60.
num_actors: 2
n_actor_envs: 16
unroll_length: 16
seed: 42
model_arch: vit_model
embedding_dim: 32
hidden_dim: 128
n_heads: 4
n_blocks: 1
device: cpu
rescale_value_input: false
obs_space_kwargs: {}
reward_space_kwargs: {}
normalize: False
debug: False

# Model params
act_space: BasicActionSpace
obs_space: BasicObsSpace
reward_space: GameResultReward

## OPTIMIZER params
optimizer_class: Adam
optimizer_kwargs:
  lr: 5e-7
  # See https://arxiv.org/pdf/2105.05246.pdf
  eps: 0.0003
  #alpha: 0.9
min_lr_mod: 0.01

## LOSS params
entropy_cost: 0.0002
baseline_cost: 1.
teacher_kl_cost: 0.005
# lambda parameter for TD-lambda and UPGO losses
lmb: 0.9
reduction: mean

# Pretrained model for KL loss
use_teacher: True
teacher_load_dir: outputs/02-17/17-20-50
teacher_checkpoint_file: 1000192_weights.pt

# MISCELLANEOUS params
actor_device: cpu
learner_device: cpu
disable_wandb: false
model_log_freq: 100
# file_descriptor or file_system
sharing_strategy: file_descriptor