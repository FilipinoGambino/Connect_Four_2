{"format": "torch", "nodes": [{"name": "dict_input_layer", "id": 1803319268160, "class_name": "DictInputLayer()", "parameters": [], "output_shape": [[[[0], [0], [0], [0]], [[0], [0], [0], [0], [0], [0], 0, [0]], [0, [0], 0, 0, 0, 0, 0, 0], [[0], [0], 0, 0, 0, [0], 0, 0, 0, 0, 0, 0], [0, [0], 0, 0, [0], 0, 0, 0, 0, 0, 0]], [136, 7], []], "num_parameters": []}, {"name": "base_model.0", "id": 1803316209120, "class_name": "ConvEmbeddingInputLayer(\n  (embeddings): ModuleDict(\n    (empty_cells): Embedding(2, 32)\n    (filled_cells): Embedding(2, 32)\n    (p1_cells): Embedding(2, 32)\n    (p2_cells): Embedding(2, 32)\n  )\n  (continuous_space_embedding): Sequential(\n    (0): Conv2d(1, 128, kernel_size=(1, 1), stride=(1, 1))\n    (1): LeakyReLU(negative_slope=0.01)\n  )\n  (embedding_merger): Sequential(\n    (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n    (1): LeakyReLU(negative_slope=0.01)\n  )\n  (merger): Sequential(\n    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n  )\n)", "parameters": [["embeddings.empty_cells.weight", [2, 32]], ["embeddings.filled_cells.weight", [2, 32]], ["embeddings.p1_cells.weight", [2, 32]], ["embeddings.p2_cells.weight", [2, 32]], ["continuous_space_embedding.0.weight", [128, 1, 1, 1]], ["continuous_space_embedding.0.bias", [128]], ["embedding_merger.0.weight", [128, 128, 1, 1]], ["embedding_merger.0.bias", [128]], ["merger.0.weight", [128, 256, 1, 1]], ["merger.0.bias", [128]]], "output_shape": [[136, 128, 6, 7]], "num_parameters": [64, 64, 64, 64, 128, 128, 16384, 128, 32768, 128]}, {"name": "base_model.1", "id": 1803316314016, "class_name": "ViTBlock(\n  (norm1): Identity()\n  (mha): MHABlock(\n    (q): AttnVector(\n      (w): Linear(in_features=128, out_features=128, bias=False)\n    )\n    (k): AttnVector(\n      (w): Linear(in_features=128, out_features=128, bias=False)\n    )\n    (v): AttnVector(\n      (w): Linear(in_features=128, out_features=128, bias=False)\n    )\n    (drop): Dropout(p=0.1, inplace=False)\n    (merge_fc): Linear(in_features=128, out_features=1, bias=True)\n  )\n  (norm2): Identity()\n  (mlp): Sequential(\n    (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n    (1): GELU(approximate='none')\n    (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n  )\n)", "parameters": [["mha.q.w.weight", [128, 128]], ["mha.k.w.weight", [128, 128]], ["mha.v.w.weight", [128, 128]], ["mha.merge_fc.weight", [1, 128]], ["mha.merge_fc.bias", [1]], ["mlp.0.weight", [128, 128, 1, 1]], ["mlp.0.bias", [128]], ["mlp.2.weight", [128, 128, 1, 1]], ["mlp.2.bias", [128]]], "output_shape": [[136, 128, 6, 7]], "num_parameters": [16384, 16384, 16384, 128, 1, 16384, 128, 16384, 128]}, {"name": "actor_base.0", "id": 1803319267872, "class_name": "Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))", "parameters": [["bias", [128]], ["weight_orig", [128, 128, 1, 1]]], "output_shape": [[136, 128, 6, 7]], "num_parameters": [128, 16384]}, {"name": "actor_base.1", "id": 1803319268496, "class_name": "ReLU()", "parameters": [], "output_shape": [[136, 128, 6, 7]], "num_parameters": []}, {"name": "actor", "id": 1803319268832, "class_name": "DictActor(\n  (actor): Conv2d(128, 7, kernel_size=(6, 7), stride=(1, 1))\n)", "parameters": [["actor.weight", [7, 128, 6, 7]], ["actor.bias", [7]]], "output_shape": [[136, 7], [136, 1]], "num_parameters": [37632, 7]}, {"name": "baseline_base.0", "id": 1803319269744, "class_name": "Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))", "parameters": [["bias", [128]], ["weight_orig", [128, 128, 1, 1]]], "output_shape": [[136, 128, 6, 7]], "num_parameters": [128, 16384]}, {"name": "baseline_base.1", "id": 1803319269936, "class_name": "ReLU()", "parameters": [], "output_shape": [[136, 128, 6, 7]], "num_parameters": []}, {"name": "baseline", "id": 1803319270080, "class_name": "BaselineLayer(\n  (linear): Linear(in_features=128, out_features=1, bias=True)\n  (activation): Sigmoid()\n)", "parameters": [["linear.weight", [1, 128]], ["linear.bias", [1]]], "output_shape": [[136, 1]], "num_parameters": [128, 1]}], "edges": []}