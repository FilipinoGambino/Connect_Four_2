#defaults:
#- override hydra/job_logging: colorlog
#- override hydra/hydra_logging: colorlog

hydra:
  run:
    dir: ./outputs/${now:%m-%d}/${now:%H-%M-%S}

name: conv_phase1
## WANDB params
# The wandb project name
project: ConnectX
# The wandb user to log to
entity: filipinogambino
# The wandb group for the run
group: conv_run

# Parameters to overwrite
use_mixed_precision: false
total_steps: 1e6
batch_size: 8
checkpoint_freq: 60.
num_actors: 2
n_actor_envs: 16
unroll_length: 16
seed: 42
model_arch: conv_model
embedding_dim: 32
hidden_dim: 128
n_blocks: 8
device: cpu
rescale_value_input: false
rescale_se_input: false
kernel_size: 3
obs_space_kwargs: {}
reward_space_kwargs: {}
normalize: false
debug: false

# Model params
act_space: BasicActionSpace
obs_space: BasicObsSpace
reward_space: GameResultReward

## OPTIMIZER params
optimizer_class: Adam
optimizer_kwargs:
  lr: 1e-5
  # See https://arxiv.org/pdf/2105.05246.pdf
  eps: 0.0003
  #alpha: 0.9
min_lr_mod: 0.01

## LOSS params
entropy_cost: 0.0002
baseline_cost: 1.
teacher_kl_cost: 0.005
# lambda parameter for TD-lambda and UPGO losses
lmb: 0.9
reduction: mean

# Pretrained model for KL loss
use_teacher: false
teacher_load_dir: none
teacher_checkpoint_file: none

# MISCELLANEOUS params
actor_device: cpu
learner_device: cpu
disable_wandb: true
model_log_freq: 100
# file_descriptor or file_system
sharing_strategy: file_descriptor